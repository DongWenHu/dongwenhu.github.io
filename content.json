[{"title":"面试之旅","date":"2017-05-15T09:38:34.000Z","path":"2017/05/15/面试之旅/","text":"其实现在已经上班有好几天了，现在才开始写这篇博客，主要是前面心情不怎么好，至于为什么就不说了。 先回忆下毕业时找工作的情景，从沈阳跑到南昌，从北跑到南去找工作，想想还是蛮艰辛的。 首先说下为什么从沈阳跑到南昌去找工作，本身就读在南昌一所大学，然后选的软件工程专业，之后分配了嵌入式方向，当时觉得嵌入式方向比较厉害些就选了它了。但嵌入式方向的专业是跟沈阳东软实训企业有合作关系的，前两年在学校修完主要课程，后两年就得到沈阳去实习，说是实习，其实就是和学校差不多，一样上课，但上课方式和学校不一样，座位是安排好的，所以有点像高中的感觉，只是比高中自由些。 毕业校招季来临时，我们不在自己的校园，想去参加校园招聘，只能通过查看东北大学的一些校招信息，然后去参加宣讲。东北大学计算机专业算是该学校最好的专业了，又是985,211，所有会有不少好的企业去东北大学校招，我的学校并不属于985,211，所以在沈阳校招方面，对于一些企业来讲，还是比较弱势，但还是有些企业并不在乎这些，你有能力就行。后面参加了一些笔试，没过，过了的笔试，面试没过，还是自己的能力不足。 接着一个多月没找到工作，有点急了，很多同学会南昌去找了，所以我也跟着回去了，也就有了从北到南的情景。接着参加宣讲笔试面试，最后去了深圳一家公司。 毕业校招竞争大，自己表达能力有不怎么行，再加上能力也不是很突出，所以好几家想去的企业都没过。 接着就不讲了… 然后毕业快3年了，想换家游戏公司，便辞去原来工作，投简历，投了挺多家游戏公司的，但简历这关都没过，主要是没有游戏开发经验，大多数游戏公司还是要求需要游戏开发经验的。接着收到一些游戏公司面试，也有一些没有投的公司也打了电话。 第一家是驱动人生，没有投过这家，不过听过，也比较有名，所以去面了，面了2轮技术面和1轮HR面，为什么开始有2个技术面呢，第一个是windows开发来面我，让我做windows开发，他面试我后，对我印象特别好，然后我说我想做的是linux开发，之后他就去找linux那边的人来面我，面了后，有些答错了，但还是让过了，接着就HR面，谈了薪资方面等内容，但下午还有个复试，然后下午面试，感觉应该是技术总监以上级别的，到最后说先回去等通知，可能还有个CTO面，我想最后那面可能没过了，不过后面也给了通知，说面试职位和当前的职位不太符合，被pass了，这家是我辞职后第一家面试，所以有些知识问到的还是没准备好。 第二家是个游戏公司，团队比较少，小游戏公司，然后赶去面试，没有笔试，一开始自我介绍，讲完后，也没对项目的问题针对去问，直接让你写代码，写不用系统函数和printf函数，打印一串整数，然后再接着写个字符串拷贝，这两个比较简单，直接写出了，然后接着回到第一个问题，用递归实现，然后也写出了，接着就不问了，直接谈薪资，我说了我的期望，他也没砍价，直接给了，然后说我简历里做的项目其实是他原来在学校里面做的项目，和我原来公司老板是同学，其实我是相信的，因为这个项目就是老板在学校里做的项目，然后带出来了，做大了。后面就让我考虑了，我就先答应了，说过段时间才能入职，主要多争取些面试机会。 第三家其实是中软的外包，开始是想多面试一些机会，但后来不想去，但她那边讲面试官都叫来了，不好又打发人家走，所以还是去了，面试很简单，就问些基础的c++，然后就说水平还行，之后虽然过了，但没有想在这里工作的想法。 第四家就是现在工作的这家，主要看到福利还行，每年国外游，然后面了1个组长面，1个CTO面，CTO面的时候就看出来了这家公司的CTO能力很强，如果在他带领下，肯定能学到不少。最后也给了offer，但也在考虑，因为砍了我的价啊，之后说太低了，给加了些，然后觉得还是太低了，接着又加了些。然后就先答应了。 第五家，迅雷，当时如果迅雷过了就去迅雷了，但是，迅雷这样的公司不单单仅注重你的技术，还有你的职业生涯规划，我就是挂在这个职业生涯规划上了。技术面第1面，问的比较多，问了1个多小时的问题，但基本还是答出来了，然后说等第二面，然而第二面的技术官在面另外一个人，需要半个小时左右，当时我是准备办最后的离职流程，需要到总部办理，然而快下班了，我就跟第一个面试官说明天再面，他也答应了，其实这个时候有些后悔，因为第二天我迟到了半个小时，迅雷那边也打电话催了，到了后，第二个面试官表情很严肃，也给他对我留下了不好的影响，然后问了些技术问题，差不多都答上来了，接着问职业规划，我说我其实想去游戏行业，听到这个，他好像有点不高兴了，再加上迟到留下不好印象的因素，接着就没下文了。算是给我的一个教训吧，以后一定要对找工作抱认真对待的态度，公司对职业生涯规划很是看重的，这个方面也必须好好去答，因为公司不想你来了没多久就辞掉这样的情况。 后面因为第四家给加了工资，我有点想去，但有点不想去，因为我想再去多面试几家找更好的机会，但想去还是打败了不想去，因为觉得福利还行，另外公司有个牛人也不错，所以就去了。 然后就在这家工作了，CTO是腾讯出来创业的牛人，服务器后台都是他架构的，自己实现的一套，现在还在研究中。。。","tags":[{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"}]},{"title":"Linux IO模式及 select、poll、epoll详解","date":"2017-04-28T09:47:29.000Z","path":"2017/04/28/Linux-IO模式及-select、poll、epoll详解/","text":"一 概念说明在进行解释之前，首先要说明几个概念： 用户空间和内核空间 进程切换 进程的阻塞 文件描述符 缓存 I/O 用户空间与内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 注：总而言之就是很耗资源 进程的阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 文件描述符fd文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 二 IO模式刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。 阻塞 I/O（blocking IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO）linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（ IO multiplexing）IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 异步 I/O（asynchronous IO）inux下的asynchronous IO其实用得很少。先看一下它的流程： 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 总结blocking和non-blocking的区别调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 各个IO Model的比较如图所示： 通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 三 I/O 多路复用之select、poll、epoll详解select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下） select1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 poll1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 一 epoll操作过程epoll操作过程需要三个接口，分别如下： 123int epoll_create(int size); //创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); int epoll_create(int size);创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);函数是对指定描述符fd执行op操作。 epfd：是epoll_create()的返回值。 op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 fd：是需要监听的fd（文件描述符） epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下： 123456789101112struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;;//events可以是以下几个宏的集合：EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 二 工作模式 epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 1. LT模式LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 2. ET模式ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 3. 总结假如有这样一个例子： 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)…… LT模式：如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。 ET模式：如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。 当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后， 读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：1234567891011121314151617181920212223while(rs)&#123; buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen &lt; 0)&#123; // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读 // 在这里就当作是该次事件已处理处. if(errno == EAGAIN)&#123; break; &#125; else&#123; return; &#125; &#125; else if(buflen == 0)&#123; // 这里表示对端的socket已正常关闭. &#125; if(buflen == sizeof(buf)&#123; rs = 1; // 需要再次读取 &#125; else&#123; rs = 0; &#125;&#125; Linux中的EAGAIN含义Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。 从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。 例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。 又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。 三 代码演示下面是一段不完整的代码且格式不对，意在表述上面的过程，去掉了一些模板代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#define IPADDRESS \"127.0.0.1\"#define PORT 8787#define MAXSIZE 1024#define LISTENQ 5#define FDSIZE 1000#define EPOLLEVENTS 100listenfd = socket_bind(IPADDRESS,PORT);struct epoll_event events[EPOLLEVENTS];//创建一个描述符epollfd = epoll_create(FDSIZE);//添加监听描述符事件add_event(epollfd,listenfd,EPOLLIN);//循环等待for ( ; ; )&#123; //该函数返回已经准备好的描述符事件数目 ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); //处理接收到的连接 handle_events(epollfd,events,ret,listenfd,buf);&#125;//事件处理函数static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf)&#123; int i; int fd; //进行遍历;这里只要遍历已经准备好的io事件。num并不是当初epoll_create时的FDSIZE。 for (i = 0;i &lt; num;i++) &#123; fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理 if ((fd == listenfd) &amp;&amp;(events[i].events &amp; EPOLLIN)) handle_accpet(epollfd,listenfd); else if (events[i].events &amp; EPOLLIN) do_read(epollfd,fd,buf); else if (events[i].events &amp; EPOLLOUT) do_write(epollfd,fd,buf); &#125;&#125;//添加事件static void add_event(int epollfd,int fd,int state)&#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&amp;ev);&#125;//处理接收到的连接static void handle_accpet(int epollfd,int listenfd)&#123; int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)&amp;cliaddr,&amp;cliaddrlen); if (clifd == -1) perror(\"accpet error:\"); else &#123; printf(\"accept a new client: %s:%d\\n\",inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件 add_event(epollfd,clifd,EPOLLIN); &#125; &#125;//读处理static void do_read(int epollfd,int fd,char *buf)&#123; int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) &#123; perror(\"read error:\"); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 &#125; else if (nread == 0) &#123; fprintf(stderr,\"client close.\\n\"); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 &#125; else &#123; printf(\"read message is : %s\",buf); //修改描述符对应的事件，由读改为写 modify_event(epollfd,fd,EPOLLOUT); &#125; &#125;//写处理static void do_write(int epollfd,int fd,char *buf) &#123; int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1)&#123; perror(\"write error:\"); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLOUT); //删除监听 &#125;else&#123; modify_event(epollfd,fd,EPOLLIN); &#125; memset(buf,0,MAXSIZE); &#125;//删除事件static void delete_event(int epollfd,int fd,int state) &#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&amp;ev);&#125;//修改事件static void modify_event(int epollfd,int fd,int state)&#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&amp;ev);&#125;//注：另外一端我就省了 四 epoll总结在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll的优点主要是一下几个方面： 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。","tags":[]},{"title":"数据结构排序总结","date":"2017-04-27T08:53:13.000Z","path":"2017/04/27/数据结构排序总结/","text":"数据结构排序总结怎么记忆稳定性： 总过四大类排序：插入、选择、交换、归并（基数排序暂且不算） 比较高级一点的（时间复杂度低一点得）shell排序，堆排序，快速排序（除了归并排序）都是不稳定的，在加上低一级的选择排序是不稳定的。 比较低级一点的（时间复杂度高一点的）插入排序，冒泡排序，归并排序，基数排序都是稳定的。 （4种不稳定，4种稳定）。 怎么记忆初始序列是否对元素的比较次数有关： 123456789101112131415161718/** * @brief 严版数据结构书代码 * 最好的情况,数组本身有序，就只需执行n-1次比较，此时时间复杂度为O(n); * 最坏的情况，数组本身逆序，要执行n(n-1)/2次，此时时间复杂度为O(n^2); */ void _insertSort(int R[], int n) &#123; int i, j, temp; for ( i = 1; i &lt; n; ++i ) &#123; if ( R[i] &lt; R[i - 1] ) &#123;//将R[i]插入有序字表 temp = R[i]; //设置哨兵 for ( j = i - 1; R[j] &gt; temp; --j ) &#123; R[j+1] = R[j]; &#125; R[j+1] = temp; &#125; &#125; &#125; 对于直接插入排序: 当最好的情况，如果原来本身就是有序的，比较次数为n-1次（分析（while (j &gt;= 0 &amp;&amp; temp &lt; R[j])）这条语句）,时间复杂度为O(n)。 当最坏的情况，原来为逆序，比较次数为2+3+…+n=(n+2)(n-1)/2次，而记录的移动次数为i+1(i=1,2…n)=(n+4)(n-1)/2次。 如果序列是随机的，根据概率相同的原则，平均比较和移动的次数为n^2/4. 123456789101112131415161718192021222324/** * @brief 严版数据结构 选择排序 * 采用\"选择排序\"对长度为n的数组进行排序,时间复杂度最好，最坏都是O(n^2) * 当最好的时候，交换次数为0次，比较次数为n(n-1)/2 * 最差的时候，也就初始降序时，交换次数为n-1次，最终的排序时间是比较与交换的次数总和， * 总的时间复杂度依然为O(n^2) */ void _selectSort(int R[], int n) &#123; int i, j, temp, index; for ( i = 0; i &lt; n; ++i ) &#123; index = i; for ( j = i + 1; j &lt; n; ++j ) &#123; if ( R[index] &gt; R[j] ) &#123; index = j;//index中存放关键码最小记录的下标 &#125; &#125; if (index != i) &#123; temp = R[i]; R[i] = R[index]; R[index] = temp; &#125; &#125; &#125; 选择排序不关心表的初始次序，它的最坏情况的排序时间与其最佳情况没多少区别，其比较次数都为 n(n-1)/2，交换次数最好的时候为0，最差的时候为n-1，尽管和冒泡排序同为O(n)，但简单选择排序性能上要优于冒泡排序。但选择排序可以 非常有效的移动元素。因此对次序近乎正确的表，选择排序可能比插入排序慢很多。12345678910111213141516171819202122/** * @brief 改进的冒泡排序 * @attention 时间复杂度，最好的情况，要排序的表本身有序，比较次数n-1,没有数据交换,时间复杂度O(n)。 * 最坏的情况，要排序的表本身逆序，需要比较n(n-1)/2次，并做等数量级的记录移动，总时间复杂度为O(n^2). */ void bubbleSort2(int R[], int n) &#123; int i, j, temp; bool flag = TRUE; //flag用来作为标记 for ( i = 0; i &lt; n &amp;&amp; flag; ++i ) &#123; flag = FALSE; for ( j = n - 1; j &gt; i; --j ) &#123; if (R[j] &lt; R[j - 1]) &#123; temp = R[j]; R[j] = R[j - 1]; R[j - 1] = temp; flag = TRUE;//如果有数据交换，则flag为true &#125; &#125; &#125; &#125; 冒泡排序：最好的情况，n-1次比较，移动次数为0，时间复杂度为O(n)。 最坏的情况，n(n-1)/2次比较，等数量级的移动，时间复杂度为O(O^2)。 12345678910111213141516171819/** * @brief 希尔排序, 对于长度为n的数组,经过 \"希尔排序\" 输出 */ void shellSort(int R[], int n) &#123; int i, j, temp; int k = n / 2; while (k &gt;= 1) &#123; for (i = k; i &lt; n; ++i) &#123; temp = R[i]; j = i - k; while (R[j] &lt; temp &amp;&amp; j &gt;= 0) &#123; R[j+k] = R[j]; j = j - k; &#125; R[j+k] = temp; &#125; k = k / 2; &#125; 希尔排序初始序列对元素的比较次数有关。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * @brief 构建 大顶堆 * @attention 个人版本，堆排序 */ void heapAdjust(int R[], int start, int end) &#123; int j, temp; temp = R[start]; for ( j = 2 * start + 1; j &lt;= end; j = j * 2 + 1 ) &#123; if ( j &lt; end &amp;&amp; R[j] &lt; R[j + 1] ) &#123; ++j; &#125; if ( temp &gt; R[j] ) &#123; break; &#125; R[start] = R[j]; start = j; &#125; R[start] = temp; &#125; /** * @brief 堆排序 * @param R为待排序的数组，size为数组的长度 * 时间复杂度:构建大(小)顶堆，完全二叉树的高度为log(n+1)，因此对每个结点调整的时间复杂度为O(logn) * 两个循环，第一个循环做的操作次数为n/2，第二个操作次数为(n-1)，因此时间复杂度为O(nlogn) */ void heapSort(int R[], int size) &#123; int i, temp; for ( i = size / 2 - 1; i &gt;= 0; --i ) &#123; heapAdjust(R, i, size); &#125; for ( i = size - 1; i &gt;= 0; --i ) &#123; temp = R[i]; R[i] = R[0]; R[0] = temp;//表尾和表首的元素交换 heapAdjust(R, 0, i - 1); //把表首的元素换成表尾的元素后，重新构成大顶堆，因为除表首的元素外 //后面的结点都满足大顶堆的条件，故heapAdjust()的第二个参数只需为0 &#125; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * @brief 将有序的长度为n的数组a[]和长度为m的b[]归并为有序的数组c[] * 只要从比较二个数列的第一个数，谁小就先取谁，取了之后在对应的数列中删除这个数。 * 然后再进行比较，如果有数列为空，那直接将另一个数列的数据依次取出即可。 * 将两个有序序列a[first...mid]和a[mid...last]合并 */ void mergeArray(int a[], int first, int mid, int last, int tmp[]) &#123; int i = first, j = mid + 1; int k = 0; while ( i &lt;= mid &amp;&amp; j &lt;= last ) &#123; if ( a[i] &lt;= a[j] ) tmp[k++] = a[i++]; else tmp[k++] = a[j++]; &#125; while ( i &lt;= mid ) &#123; tmp[k++] = a[i++]; &#125; while ( j &lt;= last ) &#123; tmp[k++] = a[j++]; &#125; for (i = 0; i &lt; k; i++) &#123;//这里千万不能丢了这个 a[first + i] = tmp[i]; &#125; &#125; /** * @brief 归并排序，其的基本思路就是将数组分成二组A，B，如果这二组组内的数据都是有序的， * 那么就可以很方便的将这二组数据进行排序。如何让这二组组内数据有序了？ * 可以将A，B组各自再分成二组。依次类推，当分出来的小组只有一个数据时， * 可以认为这个小组组内已经达到了有序，然后再合并相邻的二个小组就可以了。这样通过先 (递归) 的分解数列， * 再 (合并) 数列就完成了归并排序。 */ void mergeSort(int a[], int first, int last, int tmp[]) &#123; int mid; if ( first &lt; last ) &#123; mid = ( first + last ) / 2; mergeSort(a, first, mid, tmp); //左边有序 mergeSort(a, mid + 1, last, tmp); //右边有序 mergeArray(a, first, mid, last, tmp); &#125; &#125; 12345678910111213141516171819202122232425262728293031/** * @brief 虽然快速排序称为分治法，但分治法这三个字显然无法很好的概括快速排序的全部步骤。 * 因此我的对快速排序作了进一步的说明：挖坑填数+分治法： * @param R为待排数组，low和high为无序区 * 时间复杂度：最好O(nlogn),最坏O(n^2)，平均O(nlogn)，空间复杂度O(logn)； */ void quickSort(int R[], int low, int high) &#123; if ( low &lt; high ) &#123; int i = low, j = high, temp = R[low]; while ( i &lt; j ) &#123; //从右往左扫描，如果数组元素大于temp，则继续，直至找到第一个小于temp的元素 while ( i &lt; j &amp;&amp; R[j] &gt;= temp ) &#123; --j; &#125; if ( i &lt; j ) &#123; R[i++] = R[j]; &#125; while ( i &lt; j &amp;&amp; R[i] &lt;= temp ) &#123; ++i; &#125; if ( i &lt; j ) &#123; R[j--] = R[i]; &#125; &#125; R[i] = temp; quickSort(R, low, i - 1); quickSort(R, i + 1, high); &#125; &#125; 各排序算法整体分析 冒泡排序、插入排序、希尔排序以及快速排序对数据的有序性比较敏感，尤其是冒泡排序和插入排序； 选择排序不关心表的初始次序，它的最坏情况的排序时间与其最佳情况没多少区别，其比较次数为 n(n-1)/2，但选择排序可以 非常有效的移动元素。因此对次序近乎正确的表，选择排序可能比插入排序慢很多。 冒泡排序在最优情况下只需要经过n-1次比较即可得出结果（即对于完全正序的表），最坏情况下也要进行n(n-1)/2 次比较，与选择排序的比较次数相同，但数据交换的次数要多余选择排序，因为选择排序的数据交换次数顶多为 n-1，而冒泡排序最坏情况下的数据交换n(n-1)/2 。冒泡排序不一定要进行 趟，但由于它的记录移动次数较多，所以它的平均时间性能比插入排序要差一些。 插入排序在最好的情况下有最少的比较次数 ，但是它在元素移动方面效率非常低下，因为它只与毗邻的元素进行比较，效率比较低。 希尔排序实际上是预处理阶段优化后的插入排序，一般而言，在 比较大时，希尔排序要明显优于插入排序。 快速排序采用的“大事化小，小事化了”的思想，用递归的方法，将原问题分解成若干规模较小但与原问题相似的子问题进行求解。快速算法的平均时间复杂度为O(nlogn) ，平均而言，快速排序是基于关键字比较的内部排序算法中速度最快者；但是由于快速排序采用的是递归的方法，因此当序列的长度比较大时，对系统栈占用会比较多。快速算法尤其适用于随机序列的排序。 因此，平均而言，对于一般的随机序列顺序表而言，上述几种排序算法性能从低到高的顺序大致为：冒泡排序、插入排序、选择排序、希尔排序、快速排序。但这个优劣顺序不是绝对的，在不同的情况下，甚至可能出现完全的性能逆转。 对于序列初始状态基本有正序，可选择对有序性较敏感的如插入排序、冒泡排序、选择排序等方法 对于序列长度 比较大的随机序列，应选择平均时间复杂度较小的快速排序方法。 各种排序算法都有各自的优缺点，适应于不同的应用环境，因此在选择一种排序算法解决实际问题之前，应当先分析实际问题的类型，再结合各算法的特点，选择一种合适的算法 这里特别介绍下快速排序： 快速排序的时间主要耗费在划分操作上，对长度为k的区间进行划分，需要k-1次关键字比较。 （1）最坏的时间复杂度 最坏情况是每次划分选取的基准都是当前无序区中关键字最小（或最大）的记录，划分的结果是基准左边的子区间为空（或右边的子区间为空），而划分所得的另一个非空的子区间中记录数目，仅仅比划分前的的无序区中记录个数减少一个。 因此，快速排序必须做n-1次划分，第i次划分开始区间长度为n-i+1,所需的比较次数为n-i(1&lt;=i&lt;=n-1),故总的比较次数达到最大值：n(n-1)/2； 如果按上面给出的划分算法，每次取当前无序区的第1个记录为基准，那么当文件的记录已按递增序(或递减序)排列时，每次划分所取的基准就是当前无序区中关键字最小(或最大)的记录，则快速排序所需的比较次数反而最多。 （2）最坏的时间复杂度 在最好情况下，每次划分所取的基准都是当前无序区的”中值”记录，划分的结果是基准的左、右两个无序子区间的长度大致相等。总的关键字比较次数： 0(nlgn) （3）平均时间复杂度 尽管快速排序的最坏时间为O(n2)，但就平均性能而言，它是基于关键字比较的内部排序算法中速度最快者，快速排序亦因此而得名。它的平均时间复杂度为O(nlgn)。 （4）空间复杂度 快速排序在系统内部需要一个栈来实现递归。若每次划分较为均匀，则其递归树的高度为O(lgn)，故递归后需栈空间为O(lgn)。最坏情况下，递归树的高度为O(n)，所需的栈空间为O(n)。","tags":[]},{"title":"c++ extern,static,const,volatile关键字","date":"2017-04-26T03:02:14.000Z","path":"2017/04/26/c-extern-static-const-volatile关键字/","text":"c++ extern,static,const,volatile关键字extern作用一(和”C”一起连用)：告诉编译器编译函数时按照C的规则去翻译函数名，而C++翻译的因为有函数重载原因，翻译规则和C不一样，这样避免在库中找不到符号。C语言不支持extern “C”语法，只适用于C++，写法如下:123456789#ifdef __cplusplusextern \"C\" &#123;#endif// 正式定义。。。#ifdef __cplusplus&#125;#endif 作用二：声明函数或全局变量的作用范围的关键字，其声明的函数和变量可以在本模块活其他模块中使用默认函数是extern的，所以可以不写。全局变量就需要写，不然那会被c++看成定义式。看以下例子:123456789101112131415161718#include&lt;stdio.h&gt;namespace myname &#123; int var = 42;&#125;extern \"C\" int _ZN6myname3varE;int main()&#123; printf(\"%d\\n\", _ZN6myname3varE); myname::var ++; printf(\"%d\\n\", _ZN6myname3varE); printf(\"%p\\n\",&amp;_ZN6myname3varE); printf(\"%p\\n\", &amp;myname::var); return 0;&#125; 输出:123442430x6010400x601040 在这个例子中，我们根据g++编译器的符号修饰规则，仿造了一个C变量（gcc不进行符号修饰），欺骗了编译器，把myname::var 和 _ZN6myname3varE当成了同一个变量了。所以声明变量最好加extern staticC 语言的 static 两种用途： 1. 静态局部变量 用于函数体内部修饰变量，这种变量的生存期长于该函数。 2. 静态全局变量或函数 静态全局变量：定义在函数体外，用于修饰全局变量，表示该变量只在本文件可见。 C++ 语言的 static 两种用途： 1. 静态数据成员 生存期大于 class 的对象（实体 instance）。静态数据成员是每个 class 有一份 2. 静态成员函数 静态成员函数不能访问非静态(包括成员函数和数据成员)，但是非静态可以访问静态调用静态成员函数，可以用类名::函数名调用 const1. 定义常量 const修饰变量，变量的value是不可变的。 2. 指针使用CONST (1) 指针本身是常量不可变1char* const pContent; (2) 指针所指向的内容是常量不可变1const char* pContent; (3) 两者都不可变1const char* const pContent; 3. 类相关CONST (1) const修饰成员变量const修饰类的成员函数，表示成员常量，不能被修改，同时它只能在初始化列表中赋值。1234567class A&#123; … const int nValue; //成员常量不能被修改 … A(int x): nValue(x) &#123; &#125; ; //只能在初始化列表中赋值&#125; (2) const修饰成员函数const修饰类的成员函数，则该成员函数不能修改类中任何非const成员函数。一般写在函数的最后来修饰。123456class A&#123; … void function()const; //常成员函数, 它不改变对象的成员变量. //也不能调用类中任何非const成员函数。&#125; (3) const修饰类对象/对象指针/对象引用const修饰类对象表示该对象为常量对象，其中的任何成员都不能被修改。对于对象指针和对象引用也是一样。const修饰的对象，该对象的任何非const成员函数都不能被调用，因为任何非const成员函数会有修改成员变量的企图。123456789101112class AAA&#123; void func1(); void func2() const; &#125; const AAA aObj; aObj.func1(); //×aObj.func2(); //正确const AAA* aObj = new AAA(); aObj-&gt; func1(); //×aObj-&gt; func2(); //正确 volatilevolatile 影响编译器编译的结果,指出，volatile 变量是随时可能发生变化的，与volatile变量有关的运算，不要进行编译优化，以免出错 volatile变量的几个例子: 1) 并行设备的硬件寄存器（如：状态寄存器）2) 一个中断服务子程序中会访问到的非自动变量(Non-automatic variables)3) 多线程应用中被几个任务共享的变量 问题: 1) 一个参数既可以是const还可以是volatile吗？解释为什么。2) 一个指针可以是volatile 吗？解释为什么。3) 下面的函数有什么错误：1234int square(volatile int *ptr) &#123; return *ptr * *ptr; &#125; 答案： 1) 是的。一个例子是只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。 2) 是的。尽管这并不很常见。一个例子是当一个中服务子程序修该一个指向一个buffer的指针时。 3) 这段代码有点变态。这段代码的目的是用来返指针ptr指向值的平方，但是，由于ptr指向一个volatile型参数，编译器将产生类似下面的代码：1234567int square(volatile int *ptr) &#123; int a,b; a = *ptr; b = *ptr; return a * b; &#125; 由于*ptr的值可能被意想不到地该变，因此a和b可能是不同的。结果，这段&gt; 代码可能返不是你所期望的平方值！正确的代码如下：123456long square(volatile int *ptr) &#123; int a; a = *ptr; return a * a; &#125;","tags":[]},{"title":"c++虚函数实现原理","date":"2017-04-25T06:49:19.000Z","path":"2017/04/25/c-虚函数实现原理/","text":"c++虚函数实现原理下图中，我们在子类中覆盖了父类的f()函数: 下面是对于子类实例中的虚函数表的图: 源码参考:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146#include \"stdafx.h\"#include &lt;iostream&gt;using namespace std;class Base1 &#123;public: virtual void f() &#123; cout &lt;&lt; \"Base1::f\" &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; \"Base1::g\" &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; \"Base1::h\" &lt;&lt; endl; &#125; void g2() &#123; cout &lt;&lt; \"Base1::g2\" &lt;&lt; endl; &#125;&#125;;class Base2 &#123;public: virtual void f() &#123; cout &lt;&lt; \"Base2::f\" &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; \"Base2::g\" &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; \"Base2::h\" &lt;&lt; endl; &#125; void g2() &#123; cout &lt;&lt; \"Base2::g2\" &lt;&lt; endl; &#125;&#125;;class Base3 &#123;public: virtual void f() &#123; cout &lt;&lt; \"Base3::f\" &lt;&lt; endl; &#125; virtual void g() &#123; cout &lt;&lt; \"Base3::g\" &lt;&lt; endl; &#125; virtual void h() &#123; cout &lt;&lt; \"Base3::h\" &lt;&lt; endl; &#125; void g2() &#123; cout &lt;&lt; \"Base3::g2\" &lt;&lt; endl; &#125;&#125;;class Derive : public Base1, public Base2, public Base3 &#123;public: virtual void f() &#123; cout &lt;&lt; \"Derive::f\" &lt;&lt; endl; &#125; virtual void g1() &#123; cout &lt;&lt; \"Derive::g1\" &lt;&lt; endl; &#125; void g2() &#123; cout &lt;&lt; \"Derive::g2\" &lt;&lt; endl; &#125; // 会保存在代码区 int a = 1;&#125;;void test1()&#123; typedef void(*Fun) (void); Fun pFun = NULL; Derive d; cout &lt;&lt; \"sizeof(Derive)\" &lt;&lt; sizeof(d) &lt;&lt; endl; int** pVtab = (int**)&amp;d; // Derive::a int a = (int)*((int *)&amp;d + 3); cout &lt;&lt; a &lt;&lt; endl; //Base1's vtable //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+0)+0); pFun = (Fun)pVtab[0][0]; pFun(); //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+0)+1); pFun = (Fun)pVtab[0][1]; pFun(); //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+0)+2); pFun = (Fun)pVtab[0][2]; pFun(); //Derive's vtable //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+0)+3); pFun = (Fun)pVtab[0][3]; pFun(); //The tail of the vtable pFun = (Fun)pVtab[0][4]; cout &lt;&lt; pFun &lt;&lt; endl; //Base2's vtable //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+1)+0); pFun = (Fun)pVtab[1][0]; pFun(); //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+1)+1); pFun = (Fun)pVtab[1][1]; pFun(); pFun = (Fun)pVtab[1][2]; pFun(); //The tail of the vtable pFun = (Fun)pVtab[1][3]; cout &lt;&lt; pFun &lt;&lt; endl; //Base3's vtable //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+1)+0); pFun = (Fun)pVtab[2][0]; pFun(); //pFun = (Fun)*((int*)*(int*)((int*)&amp;d+1)+1); pFun = (Fun)pVtab[2][1]; pFun(); pFun = (Fun)pVtab[2][2]; pFun(); //The tail of the vtable pFun = (Fun)pVtab[2][3]; cout &lt;&lt; pFun &lt;&lt; endl;&#125;int _tmain(int argc, _TCHAR* argv[])&#123; test1(); return 0;&#125; 输出: 安全性一、通过父类型的指针访问子类自己的虚函数 我们知道，子类没有重载父类的虚函数是一件毫无意义的事情。因为多态也是要基于函数重载的。虽然在上面的图中我们可以看到Base1的虚表中有Derive的虚函数，但我们根本不可能使用下面的语句来调用子类的自有虚函数： Base1 *b1 = new Derive(); b1-&gt;f1(); //编译出错 任何妄图使用父类指针想调用子类中的未覆盖父类的成员函数的行为都会被编译器视为非法，所以，这样的程序根本无法编译通过。但在运行时，我们可以通过指针的方式访问虚函数表来达到违反C++语义的行为。 二、访问non-public的虚函数 另外，如果父类的虚函数是private或是protected的，但这些非public的虚函数同样会存在于虚函数表中，所以，我们同样可以使用访问虚函数表的方式来访问这些non-public的虚函数，这是很容易做到的。","tags":[]},{"title":"Linux 守护进程","date":"2017-04-24T10:20:19.000Z","path":"2017/04/24/Linux-守护进程/","text":"如何实现守护进程1、在后台运行 为了避免挂起终端退出，在进程中调用fork,然后使父进程退出,变成孤儿进程后在后台运行，此时子进程由init进程收养123if(pid=fork()) exit(0);//是父进程，结束父进程，子进程继续 &gt; 2、脱离控制终端，登录会话和进程组 控制终端，登录会话和进程组通常是从父进程继承下来的。我们的目的就是要摆脱它们，使之不受它们的影响。方法是在第1点的基础上，调用setsid()使进程成为会话组长12setsid();&gt; 3、 禁止进程重新打开控制终端 进程已经成为无终端的会话组长。但它可以重新申请打开一个控制终端。可以通过使进程不再成为会话组长来禁止进程重新打开控制终端123if(pid=fork()) exit(0);//结束第一子进程，第二子进程继续（第二子进程不再是会话组长）&gt; 4、关闭打开的文件描述符 进程从创建它的父进程那里继承了打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。按如下方法关闭它们1234 #define NOFILE 256 ;//不同系统中不同数值 for（i=0；i&lt;NOFILE;i++） colse(i);&gt; 5、改变当前工作目录 进程活动时，其工作目录所在的文件系统不能卸下。一般需要将工作目录改变到根目录。对于需要转储核心，写运行日志的进程将工作目录改变到特定目录如/tmpchdir(“/“)12chdir(\"/\");&gt; 6、重设文件创建掩码 进程从创建它的父进程那里继承了文件创建掩模。它可能修改守护进程所创建的文件的存取位。为防止这一点，将文件创建掩模清除012umask(0);&gt; 7、处理SIGCHLD(子进程退出信号)信号 处理SIGCHLD信号并不是必须的。但对于某些进程，特别是服务器进程往往在请求到来时生成子进程处理请求。如果父进程不等待子进程结束，子进程 将成为僵尸进程（zombie）从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地 将SIGCHLD信号的操作设为SIG_IGN12signal(SIGCHLD,SIG_IGN);&gt;","tags":[]},{"title":"C++ 进程内存空间分布","date":"2017-04-24T05:44:57.000Z","path":"2017/04/24/C-进程内存空间分布/","text":"C++ 进程内存空间分布内存可以分为以下几段： 文本段：包含实际要执行的代码（机器指令）和常量。它通常是共享的，多个实例之间共享文本段。文本段是不可修改的。 初始化数据段：包含程序已经初始化的全局变量，.data。 未初始化数据段：包含程序未初始化的全局变量，.bbs。该段中的变量在执行之前初始化为0或NULL。 栈：由系统管理，由高地址向低地址扩展。 堆：动态内存，由用户管理。通过malloc/alloc/realloc、new/new[]申请空间，通过free、delete/delete[]释放所申请的空间。由低地址想高地址扩展。","tags":[]},{"title":"Linux 共享内存实现原理","date":"2017-04-24T03:22:48.000Z","path":"2017/04/24/Linux-共享内存实现原理/","text":"Linux 共享内存实现原理1、共享内存的实现采用了内存映射技术2、共享内存主要集中3个内核函数，do_shmat、sys_shmat、sys_shmdt3、sys_shmat调用do_shmat实现内存共享的attach4、sys_shmdt实现内存共享的detach和destroy，首先查找相应的vma，如果找到执行ummap操作do_shmat原理当系统提出attach或创建共享内存时，内核会为每一个共享内存段提供一个shmid_kernel的数据结构:123456789101112131415struct shmid_kernel /* private to the kernel */&#123; struct kern_ipc_perm shm_perm; // 访问权限的信息 struct file * shm_file; // 指向虚拟文件系统的指针 unsigned long shm_nattch; // 有多少个进程attach上了这个共享内存段 unsigned long shm_segsz; // 共享内存段大小 // 以下是一些访问时间的相关信息 time_t shm_atim; time_t shm_dtim; time_t shm_ctim； pid_t shm_cprid; pid_t shm_lprid; struct user_struct *mlock_user;&#125;; struct file定义参考如下:123456789101112131415161718192021222324252627282930313233struct file &#123; /* * fu_list becomes invalid after file_free is called and queued via * fu_rcuhead for RCU freeing */ union &#123; struct list_head fu_list; struct rcu_head fu_rcuhead; &#125; f_u; struct path f_path;#define f_dentry f_path.dentry#define f_vfsmnt f_path.mnt const struct file_operations *f_op; atomic_t f_count; unsigned int f_flags; mode_t f_mode; loff_t f_pos; struct fown_struct f_owner; unsigned int f_uid, f_gid; struct file_ra_state f_ra; unsigned long f_version;#ifdef CONFIG_SECURITY void *f_security;#endif /* needed for tty driver, and maybe others */ void *private_data;#ifdef CONFIG_EPOLL /* Used by fs/eventpoll.c to link all the hooks to this file */ struct list_head f_ep_links; spinlock_t f_ep_lock;#endif /* #ifdef CONFIG_EPOLL */ struct address_space *f_mapping;&#125;; 1、该数据结构中最重要的字段就是shm_file，它指向了共享内存对应的虚拟文件2、shm_file中的f_mapping指向了该内存段使用的页面(物理内存)3、当进程创建或attach共享内存时，在用户态先向虚拟内存系统申请各自的vma_struct, 内部成员vm_file指向shm_file4、这样就完成了虚拟内存, 共享内存(文件系统)和物理内存的连接","tags":[]},{"title":"Linux 虚拟内存机制","date":"2017-04-21T01:33:31.000Z","path":"2017/04/21/Linux-虚拟内存机制/","text":"Linux 虚拟内存机制1. 虚拟内存概念1、每个进程有一个独立的4G内存空间，每个进程内存空间都具有类似的结构2、每当一个新进程建立时，会建立一个自己的内存空间，将进程的数据，代码从磁盘拷贝到改内存空间，这些信息会记录在task_struct链表中。3、每个进程对应的空间都和磁盘的空间是映射的。4、每个进程的4G空间只是虚拟内存空间，每次访问时都要翻译为真实的物理地址5、所有进程共享一个物理内存，每个进程只把自己当前需要的虚拟地址空间映射并存到物理内存6、进程要知道哪些地址在物理内存上，哪些不在，在物理内存的哪一个地方，需要用页表来记录7、当进程访问某个虚拟地址，去看页表，发现不在物理内存中，则发生缺页异常8、缺页异常就是把需要的数据从磁盘拷贝到物理内存，如果内存满了就找一个页覆盖 补充理解:虚拟内存起初都是映射到磁盘空间（mmap），并由页表记录映射位置，当访问到某个地址的时候，查看页表发现不在物理内存，就通过缺页异常，将数据从磁盘拷贝到物理内存，如果没有空闲内存，则牺牲页面，替换其他页面。 2. 虚拟内存优点1、每个进程空间内存地址固定2、不同进程使用同一份代码，比如库文件，物理内存保存一份，虚拟内存映射过去就可以了，节省内存3、程序分配内存时，只需在虚拟内存连续分配空间，无需实际内存的连续空间，可以利用碎片 3. 虚拟内存管理方式linux系统有两种方法进行内存管理，“调页算法”和“交换技术”调页算法：将内存不经常使用的页面换到磁盘，常用的页面(活动页面)保留在内存 交换技术：系统将整个进程，而不是部分页面，全部换到磁盘","tags":[]},{"title":"Linux常用命令","date":"2017-04-20T02:30:14.000Z","path":"2017/04/20/Linux常用命令/","text":"Linux 常用命令有哪些？1. 网络相关和进程活动相关1netstat 监控TCP/IP网络非常有用的工具，查看路由表、网络连接和端口状态等信息 1tcpdump 对网络上的数据包进行截获的包分析工具 1ipcs 往标准输出写入一些关于活动进程间通信设施的信息 1ipcrm 删除一个或更多的消息队列、信号量集或者共享内存标识 2. 系统性能相关12$ uptime2:07pmup 11 days,4:54, 9 users, load average: 1.90, 1.98, 2.01 我们可以使用uptime命令来监视Linux系统性能和状态，这是一种非常有效的简单方法。uptime命令会显示在一定时间间隔内系统运行队列中进程的信息。通过这些信息可以大致地分析系统的工作负载。所以当系统性能下降时，首先应使用uptime命令来观察系统运行队列中进程的情况。 在上面显示内容其中有用的信息是三个负载的平均值：1.90、1.98和2.01分别是前1分钟、5分钟和15分钟内的负载平均值。 系统管理员需要定期运行uptime命令以观察系统的平均负载值及其变化趋势。系统的问题往往通过上述数据反映出来。当系统负载增大时，说明多条命令被阻塞在内存和I/O系统中。这时需要检查系统的有关信息。一般Linux系统，负载为2和3表示轻载，5和6表示中等程度负载，10以上为过载。不同系统的划分标准是不同的。系统管理员应根据实际情况确定自己系统中划分轻载和过载的界限。 1free 查看系统中内存空间的大小1top 动态实时的察看系统性能，分析CPU、内存的使用资源以及相关进程的信息等1vmstat 可对操作系统的虚拟内存、进程、CPU活动进行监视。它对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析 3. 文件处理相关1awk 主要是以行为单位进行处理，以指定字符分割(默认空格)，然后对分割的部分进行各种分析1sed 主要是以行为单位进行处理，将数据进行替换、删除、新增、选取等工作","tags":[]},{"title":"Markdown 写法","date":"2017-04-19T08:15:07.000Z","path":"2017/04/19/Markdown 写法/","text":"欢迎使用 Cmd Markdown 编辑阅读器 我们理解您需要更便捷更高效的工具记录思想，整理笔记、知识，并将其中承载的价值传播给他人，Cmd Markdown 是我们给出的答案 —— 我们为记录思想和分享知识提供更专业的工具。 您可以使用 Cmd Markdown： 整理知识，学习笔记 发布日记，杂文，所见所想 撰写发布技术文稿（代码支持） 撰写发布学术论文（LaTeX 公式支持） 除了您现在看到的这个 Cmd Markdown 在线版本，您还可以前往以下网址下载： Windows/Mac/Linux 全平台客户端 请保留此份 Cmd Markdown 的欢迎稿兼使用说明，如需撰写新稿件，点击顶部工具栏右侧的 新文稿 或者使用快捷键 Ctrl+Alt+N。 什么是 MarkdownMarkdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，粗体 或者 斜体 某些文字，更棒的是，它还可以 1. 制作一份待办事宜 Todo 列表 [ ] 支持以 PDF 格式导出文稿 [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 [x] 新增 Todo 列表功能 [x] 修复 LaTex 公式渲染问题 [x] 新增 LaTex 公式编号功能 2. 书写一个质能守恒公式[^LaTeX]$$E=\\mc^2$$ 3. 高亮一段代码[^code]1234567@requires_authorizationclass SomeClass: passif __name__ == '__main__': # A comment print 'hello world' 4. 高效绘制 流程图12345678st=&gt;start: Startop=&gt;operation: Your Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 5. 高效绘制 序列图123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! 6. 高效绘制 甘特图12345678910111213title 项目开发流程section 项目确定 需求分析 :a1, 2016-06-22, 3d 可行性报告 :after a1, 5d 概念验证 : 5dsection 项目实施 概要设计 :2016-07-05 , 5d 详细设计 :2016-07-08, 10d 编码 :2016-07-15, 10d 测试 :2016-07-22, 5dsection 发布验收 发布: 2d 验收: 3d 7. 绘制表格 项目 价格 数量 计算机 \\$1600 5 手机 \\$12 12 管线 \\$1 234 8. 更详细语法说明想要查看更详细的语法说明，可以参考我们准备的 Cmd Markdown 简明语法手册，进阶用户可以参考 Cmd Markdown 高阶语法手册 了解更多高级功能。 总而言之，不同于其它 所见即所得 的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式。 什么是 Cmd Markdown您可以使用很多工具书写 Markdown，但是 Cmd Markdown 是这个星球上我们已知的、最好的 Markdown 工具——没有之一 ：）因为深信文字的力量，所以我们和你一样，对流畅书写，分享思想和知识，以及阅读体验有极致的追求，我们把对于这些诉求的回应整合在 Cmd Markdown，并且一次，两次，三次，乃至无数次地提升这个工具的体验，最终将它演化成一个 编辑/发布/阅读 Markdown 的在线平台——您可以在任何地方，任何系统/设备上管理这里的文字。 1. 实时同步预览我们将 Cmd Markdown 的主界面一分为二，左边为编辑区，右边为预览区，在编辑区的操作会实时地渲染到预览区方便查看最终的版面效果，并且如果你在其中一个区拖动滚动条，我们有一个巧妙的算法把另一个区的滚动条同步到等价的位置，超酷！ 2. 编辑工具栏也许您还是一个 Markdown 语法的新手，在您完全熟悉它之前，我们在 编辑区 的顶部放置了一个如下图所示的工具栏，您可以使用鼠标在工具栏上调整格式，不过我们仍旧鼓励你使用键盘标记格式，提高书写的流畅度。 3. 编辑模式完全心无旁骛的方式编辑文字：点击 编辑工具栏 最右侧的拉伸按钮或者按下 Ctrl + M，将 Cmd Markdown 切换到独立的编辑模式，这是一个极度简洁的写作环境，所有可能会引起分心的元素都已经被挪除，超清爽！ 4. 实时的云端文稿为了保障数据安全，Cmd Markdown 会将您每一次击键的内容保存至云端，同时在 编辑工具栏 的最右侧提示 已保存 的字样。无需担心浏览器崩溃，机器掉电或者地震，海啸——在编辑的过程中随时关闭浏览器或者机器，下一次回到 Cmd Markdown 的时候继续写作。 5. 离线模式在网络环境不稳定的情况下记录文字一样很安全！在您写作的时候，如果电脑突然失去网络连接，Cmd Markdown 会智能切换至离线模式，将您后续键入的文字保存在本地，直到网络恢复再将他们传送至云端，即使在网络恢复前关闭浏览器或者电脑，一样没有问题，等到下次开启 Cmd Markdown 的时候，她会提醒您将离线保存的文字传送至云端。简而言之，我们尽最大的努力保障您文字的安全。 6. 管理工具栏为了便于管理您的文稿，在 预览区 的顶部放置了如下所示的 管理工具栏： 通过管理工具栏可以： 发布：将当前的文稿生成固定链接，在网络上发布，分享 新建：开始撰写一篇新的文稿 删除：删除当前的文稿 导出：将当前的文稿转化为 Markdown 文本或者 Html 格式，并导出到本地 列表：所有新增和过往的文稿都可以在这里查看、操作 模式：切换 普通/Vim/Emacs 编辑模式 7. 阅读工具栏 通过 预览区 右上角的 阅读工具栏，可以查看当前文稿的目录并增强阅读体验。 工具栏上的五个图标依次为： 目录：快速导航当前文稿的目录结构以跳转到感兴趣的段落 视图：互换左边编辑区和右边预览区的位置 主题：内置了黑白两种模式的主题，试试 黑色主题，超炫！ 阅读：心无旁骛的阅读模式提供超一流的阅读体验 全屏：简洁，简洁，再简洁，一个完全沉浸式的写作和阅读环境 8. 阅读模式在 阅读工具栏 点击 或者按下 Ctrl+Alt+M 随即进入独立的阅读模式界面，我们在版面渲染上的每一个细节：字体，字号，行间距，前背景色都倾注了大量的时间，努力提升阅读的体验和品质。 9. 标签、分类和搜索在编辑区任意行首位置输入以下格式的文字可以标签当前文档： 标签： 未分类 标签以后的文稿在【文件列表】（Ctrl+Alt+F）里会按照标签分类，用户可以同时使用键盘或者鼠标浏览查看，或者在【文件列表】的搜索文本框内搜索标题关键字过滤文稿，如下图所示： 10. 文稿发布和分享在您使用 Cmd Markdown 记录，创作，整理，阅读文稿的同时，我们不仅希望它是一个有力的工具，更希望您的思想和知识通过这个平台，连同优质的阅读体验，将他们分享给有相同志趣的人，进而鼓励更多的人来到这里记录分享他们的思想和知识，尝试点击 (Ctrl+Alt+P) 发布这份文档给好友吧！ 再一次感谢您花费时间阅读这份欢迎稿，点击 (Ctrl+Alt+N) 开始撰写新的文稿吧！祝您在这里记录、阅读、分享愉快！ 作者 @ghosert2016 年 07月 07日 [^LaTeX]: 支持 LaTeX 编辑显示支持，例如：$\\sum_{i=1}^n a_i=0$， 访问 MathJax 参考更多使用方法。 [^code]: 代码高亮功能支持包括 Java, Python, JavaScript 在内的，四十一种主流编程语言。","tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://yoursite.com/tags/Markdown/"},{"name":"标签1","slug":"标签1","permalink":"http://yoursite.com/tags/标签1/"}]},{"title":"Hello World","date":"2017-04-11T09:38:34.000Z","path":"2017/04/11/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]